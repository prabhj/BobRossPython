{"cells":[{"cell_type":"markdown","source":["## Objectives\n* Practice k-means clustering\n* Gain experience moving between pandas and Spark (both ways)\n\n### * Name: Prabhjot Singh\n### * I worked myself."],"metadata":{}},{"cell_type":"markdown","source":["## Background\n\n#### Refer Read.me"],"metadata":{}},{"cell_type":"markdown","source":["### As a first step, let's load the libraries we need:"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom PIL import Image\nimport seaborn as sns\nimport matplotlib.cm as cm\nimport re\nimport os.path"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":["### Getting the data from Amazon Web Services S3\n\nWe need the CSV file with data (bob_ross.csv), as well as a collection of images to complete this assignment.\nOne way for us to share those with you is to put them in an AWS S3 bucket and get you to \"mount\" that bucket\nas a directory that's accessible via this notebook.\n\nThe following code block does exactly that, making the bucket containing those files available to this notebook.  To Spark, it will look like the files live in a directory called ```/mnt/si330w18```.  \nTo pandas, which we will use to read the data, the files will live in ```/dbfs/mnt/si330w18```.  Note the use of ```/dbfs``` as a prefix in the pandas version.\nAt the end of the code block is a command to list the contents of the \nmounted S3 bucket."],"metadata":{}},{"cell_type":"code","source":["ACCESS_KEY = \"AKIAIPKMRL4G3IEVQ7FQ\"\nSECRET_KEY = \"bkG5SUmSc+S8bQseSo8SaBAHQtt3xGUfRlOojUrW\"\nENCODED_SECRET_KEY = SECRET_KEY.replace(\"/\", \"%2F\")\nAWS_BUCKET_NAME = \"umsi-data-science-west\"\nMOUNT_NAME = \"umsi-data-science\"\ntry:\n  dbutils.fs.unmount(\"/mnt/%s/\" % MOUNT_NAME)\nexcept:\n  print(\"Could not unmount %s, but that's ok.\" % MOUNT_NAME)\ndbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)\ndisplay(dbutils.fs.ls(\"/mnt/umsi-data-science/si618wn2017\"))"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["### Defining a helper function to simplify the color space of images\nThe next code block sets up a utility function (```getColors```), which takes an image and figures out which colors are used.\nIt reduces the color space to about 85 colors (from an original space of 65536 colors) and returns the normalized count of \neach color's appearance in the image.\n\nThe function takes as input the filename of an image file.  It opens the file and sets up a numpy array of zeros for each of the\n85 output colors.  The function then goes through all of the pixels in the image and calculates the red, green and blue \ncolor values in the reduced space (that's why we divide each of the values for red, green and blue by 63).  We then put\nthe red, green and blue values back together again by bit-shifting the green and blue values and then using a logical 'or'.\nLet's say we had a color of 126,189,252 (which is an pleasant blue color).  Dividing those values by 63, we get 2,3,4.\nBit-shifting 3 << 2 gives us 12, 4 << 4 gives us 64.  We don't bit-shift the red values, so we just keep the 2.  Adding those\ntogether (equivalent to using a logical \"or\" on the bit-shifted values) gives us 78, so we would increment the count of color 78.\n\nFinally, we convert all counts to proportions and return the proportions of each color as a numpy array."],"metadata":{}},{"cell_type":"code","source":["def getColors(img):\n    im = Image.open(img, 'r')\n    width, height = im.size\n    #print(img,width,height)\n    pixel_values = list(im.getdata())\n    cnt = np.zeros(85,dtype=int)\n    for i in pixel_values:\n        #print(i)\n        r = int(i[0]/63)\n        g = int(i[1]/63)<<2\n        b = int(i[2]/63)<<4\n        x = r | g | b\n        #print(x)\n        cnt[x] = cnt[x] + 1\n        #print(cnt[x])\n    cnt = cnt/float(sum(cnt))\n    return(cnt)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Loading the \"tags' file into a pandas DataFrame\nFirst, we're going to load the CSV file of the human-assigned tags for each of Bob's paintings into a **pandas** DataFrame.  Remember that we mounted the AWS S3 bucket containing the data as ```/mnt/umsi-data-science/si618wn2017``` and the CSV file is named ```bob_ross.csv```.  We can read the file using the (hopefully)\nfamiliar ```.from_csv()``` method in pandas:"],"metadata":{}},{"cell_type":"code","source":["bob_ross = pd.DataFrame.from_csv(\"/dbfs/mnt/umsi-data-science/si618wn2017/bob_ross.csv\")"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["Let's take a look at the contents:"],"metadata":{}},{"cell_type":"code","source":["bob_ross.head()"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["The above command should show you that you have a pandas DataFrame with 5 rows and 68 columns.  These are the \"tags\" for each of the images that\nwe will load.  The tags were generated by people, and indicate the presence or absence of various features (e.g. \"BEACH\"), which is set to 1 if the \nfeature is present or 0 if the feature is not present."],"metadata":{}},{"cell_type":"markdown","source":["## NOTE: The next code block takes a very long time (about 5 minutes) to complete.  Wait for it!"],"metadata":{}},{"cell_type":"code","source":["bob_ross['image'] = \"\"\n# create a column for each of the 85 colors (these will be c0...c84)\n# we'll do this in a separate table for now and then merge\ncols = ['c%s'%i for i in np.arange(0,85)]\ncolors = pd.DataFrame(columns=cols)\ncolors['EPISODE'] = bob_ross.index.values\ncolors = colors.set_index('EPISODE')\n\n# figure out if we have the image or not, we don't have a complete set\nfor s in bob_ross.index.values:\n    b = bob_ross.loc[s]['TITLE']\n    b = b.lower()\n    b = re.sub(r'[^a-z0-9\\s]', '',b)\n    b = re.sub(r'\\s', '_',b)\n    img = b+\".png\"\n    if (os.path.exists(\"/dbfs/mnt/umsi-data-science/si618wn2017/images/\"+img)):\n        bob_ross.set_value(s,\"image\",\"/dbfs/mnt/umsi-data-science/si618wn2017/images/\"+img)\n        t = getColors(\"/dbfs/mnt/umsi-data-science/si618wn2017/images/\"+img)\n        colors.loc[s] = t\n"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# join the colors and tag database and toss the rows where we don't have an image\nbob_ross = bob_ross.join(colors)\nbob_ross = bob_ross[bob_ross.image != \"\"] "],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["# these are masks you might find handy to only get the colors, the tags, or both (as well as the image path)\ncolor_columns = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10',\n               'c11', 'c12', 'c13', 'c14', 'c15', 'c16', 'c17', 'c18', 'c19', 'c20',\n               'c21', 'c22', 'c23', 'c24', 'c25', 'c26', 'c27', 'c28', 'c29', 'c30',\n               'c31', 'c32', 'c33', 'c34', 'c35', 'c36', 'c37', 'c38', 'c39', 'c40',\n               'c41', 'c42', 'c43', 'c44', 'c45', 'c46', 'c47', 'c48', 'c49', 'c50',\n               'c51', 'c52', 'c53', 'c54', 'c55', 'c56', 'c57', 'c58', 'c59', 'c60',\n               'c61', 'c62', 'c63', 'c64', 'c65', 'c66', 'c67', 'c68', 'c69', 'c70',\n               'c71', 'c72', 'c73', 'c74', 'c75', 'c76', 'c77', 'c78', 'c79', 'c80',\n               'c81', 'c82', 'c83', 'c84']\ntag_columns = ['APPLE_FRAME', 'AURORA_BOREALIS', 'BARN', 'BEACH', 'BOAT',\n       'BRIDGE', 'BUILDING', 'BUSHES', 'CABIN', 'CACTUS', 'CIRCLE_FRAME',\n       'CIRRUS', 'CLIFF', 'CLOUDS', 'CONIFER', 'CUMULUS', 'DECIDUOUS',\n       'DIANE_ANDRE', 'DOCK', 'DOUBLE_OVAL_FRAME', 'FARM', 'FENCE', 'FIRE',\n       'FLORIDA_FRAME', 'FLOWERS', 'FOG', 'FRAMED', 'GRASS', 'GUEST',\n       'HALF_CIRCLE_FRAME', 'HALF_OVAL_FRAME', 'HILLS', 'LAKE', 'LAKES',\n       'LIGHTHOUSE', 'MILL', 'MOON', 'MOUNTAIN', 'MOUNTAINS', 'NIGHT', 'OCEAN',\n       'OVAL_FRAME', 'PALM_TREES', 'PATH', 'PERSON', 'PORTRAIT',\n       'RECTANGLE_3D_FRAME', 'RECTANGULAR_FRAME', 'RIVER', 'ROCKS',\n       'SEASHELL_FRAME', 'SNOW', 'SNOWY_MOUNTAIN', 'SPLIT_FRAME', 'STEVE_ROSS',\n       'STRUCTURE', 'SUN', 'TOMB_FRAME', 'TREE', 'TREES', 'TRIPLE_FRAME',\n       'WATERFALL', 'WAVES', 'WINDMILL', 'WINDOW_FRAME', 'WINTER',\n       'WOOD_FRAMED']\nall_columns = color_columns + tag_columns + ['image']\ncolor_columns = color_columns + ['image']\ntag_columns = tag_columns + ['image']"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["# this is a utility function for displaying a grid of images, with an optional heading\ndef display_images(imagelist,cluster_title=None):\n    a = imagelist.apply(lambda x: re.search('(\\w+.png)', x).group(1))\n    np.zeros(7-len(a)%7,dtype=np.str)\n    a = np.append(a,np.zeros(7-len(a)%7,dtype=np.str))\n    grid = a.reshape(int(len(a)/7),7)\n    text = \"\"\n    if (cluster_title != None):\n       text = \"<h1>\"+cluster_title+\"</h1>\\n\" \n    text = text + \"<table>\"\n    for i in np.arange(0,len(grid)):\n        row = grid[i]\n        line = ''.join( [\"\\n<TD><img style='width: 120px; margin: 0px; float: left; border: 1px solid black;' src='https://s3.amazonaws.com/si618image/images/%s' /></TD>\" % str(s) for s in row])\n        text = text + \"<TR>\"+line+\"</TR>\\n\"\n    text = text +\"</table>\"\n    displayHTML(text)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["# for example, we can display the first 12 images\ndisplay_images(bob_ross.image,\"sample images\")"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["## K-means\n### 1) K-Means on tags (2 clusters)\n\nWe're going to start by replicating the fivethirtyeight article a bit.  Using *only* the tags, perform a k-means clustering with 2 clusters. Use display_images to show the images from each cluster.\n\n**We are going to move our data into Spark for this analysis.**"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.clustering import KMeans\nfrom pyspark.ml.evaluation import ClusteringEvaluator\nfrom pyspark.ml.feature import VectorAssembler\n\ntags = spark.createDataFrame(bob_ross[tag_columns[:-1]])\n\nassembler = VectorAssembler(\n    inputCols=tag_columns[:-1],\n    outputCol=\"features\")\n\ntags_assembled = assembler.transform(tags)\n\n\n# create a k-means model, k=2, and fit the data\nkmeans = KMeans().setK(2).setSeed(1)\nkmeans_model = kmeans.fit(tags_assembled.select(\"features\"))\n\n# Make predictions\ntags_predictions = kmeans_model.transform(tags_assembled)"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["### Now move back into pandas..."],"metadata":{}},{"cell_type":"code","source":["bob_ross[\"prediction\"] = tags_predictions.select(\"prediction\").toPandas().set_index(bob_ross.index)\n\ndf_0 = bob_ross[bob_ross[\"prediction\"] == 0]\ndisplay_images(df_0['image'],\" Cluster 1 Images\")"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["df_1 = bob_ross[bob_ross[\"prediction\"] == 1]\ndisplay_images(df_1['image'],\"Cluster 2 Images\")"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["### 2) Describe the differences\n\nWithout any further analysis, is there something obviously different about what's in the images?\n\n**Your answer**:\nIn cluster 1, all images contain mountains as well as trees, whereas, in cluster 2, majority of images contain just trees."],"metadata":{}},{"cell_type":"markdown","source":["### 3) Calculate the differences between clusters\n\nOne thing we can do to compare the clusters is to determine which tags show up more in the first cluster and which ones appear more in the second. Write code to determine which tags are maximally different between the two clusters.  You should get output that looks like:\n```\nMOUNTAIN              0.967647\nSNOWY_MOUNTAIN        0.681513\nMOUNTAINS             0.638655\nCONIFER               0.515126\nLAKE                  0.294958\n```\n\nHint: you can do this with some combination of masks, .mean() and .sort_values() all in one line (but feel free to write a loop if it's easier to think about)"],"metadata":{}},{"cell_type":"code","source":["# YOUR CODE HERE\n\ndf_means = df_1[tag_columns].mean() - df_0[tag_columns].mean()\ndf_sorted = df_means.abs().sort_values(ascending=False)\ndf_sorted\n"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["### 4) Find a better value of k\n\nDetermine a better value for k (you can use the \"rule of thumb\" approach, silhoutte scores, or scree plots... though as a warning, some of these may not be as \"clear\" as the examples in class).  \n\n**Use display_images to show the different clusters, pick the best value of k, and describe your clusters qualitatively.**"],"metadata":{}},{"cell_type":"code","source":["# method 1: \"Rule of Thumb\"\nguess = np.sqrt(tags_predictions.count()/2)\nprint(\"Within Set Sum of Squared Errors = \" + str(guess))\n# print the results"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["# method 2: Scree plot\ncost = list()\nfor k in range(2,11):\n    bkm = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    bkm_model = bkm.fit(tags_assembled)\n    cost.append(bkm_model.computeCost(tags_assembled)/k)\nprint(cost)\n# print the results"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["fig, ax = plt.subplots()\nplt.plot(range(2,11), cost, 'b*-')\nplt.xlabel('Number of clusters');\nplt.ylabel('Within Set Sum of Squared Error');\nplt.title('Elbow for K-Means clustering');\n# Uncomment the next line\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# method 3: Silhouette scores\ncost = list()\nevaluator = ClusteringEvaluator()\nfor k in range(2,11):\n    bkm = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    bkm_model = bkm.fit(tags_assembled)\n    tags_predictions = bkm_model.transform(tags_assembled)\n    silhouette = evaluator.evaluate(tags_predictions)\n    cost.append(silhouette)\n    \nkIdx = np.argmax(cost)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,11), cost, 'b*-')\nplt.plot(range(2,11)[kIdx], cost[kIdx], marker='o', markersize=12, \n         markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\nplt.xlim(1, plt.xlim()[1])\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Coefficient')\nplt.title('Silhouette Scores for k-means clustering')\n# Uncomment the next line\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["### 5) k-means based on colors\nPerform k-means clustering on the paintings using *only* the color columns. Decide a good value for k, execute the clustering, display the images in each clusters, and describe the resulting clusters."],"metadata":{}},{"cell_type":"markdown","source":["#### 5.1) For k = 4"],"metadata":{}},{"cell_type":"code","source":["colors = spark.createDataFrame(bob_ross[color_columns[:-1]])\n\nassembler = VectorAssembler(\n    inputCols=color_columns[:-1],\n    outputCol=\"features\")\n\ncolors_assembled = assembler.transform(colors)\n\n\n# create a k-means model, k=4, and fit the data\nkmeans = KMeans().setK(4).setSeed(1)\nkmeans_model = kmeans.fit(colors_assembled.select(\"features\"))\n\n# Make predictions\ncolors_predictions = kmeans_model.transform(colors_assembled)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["#clustering column - prediction\nbob_ross[\"prediction\"] = colors_predictions.select(\"prediction\").toPandas().set_index(bob_ross.index)\n\ndf_c0 = bob_ross[bob_ross[\"prediction\"] == 0]\ndisplay_images(df_c0['image'],\" Cluster 1 Images (By color)\")"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":["#### Analysis : On observing the above cluster, we find that all images 'very bright' in color (whitish)."],"metadata":{}},{"cell_type":"code","source":["df_c1 = bob_ross[bob_ross[\"prediction\"] == 1]\ndisplay_images(df_c1['image'],\" Cluster 2 Images (By color)\")"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":["#### Analysis : On observing the above cluster, we find that all images 'pale' in color (yellowish)."],"metadata":{}},{"cell_type":"code","source":["df_c2 = bob_ross[bob_ross[\"prediction\"] == 2]\ndisplay_images(df_c2['image'],\" Cluster 3 Images (By color)\")"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":["#### Analysis : On observing the above cluster, we find that all images 'very dark' in color (blackish)."],"metadata":{}},{"cell_type":"code","source":["df_c3 = bob_ross[bob_ross[\"prediction\"] == 3]\ndisplay_images(df_c3['image'],\" Cluster 4 Images (By color)\")"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"markdown","source":["#### Analysis : On observing the above cluster, we find that all images again 'pale blue' in color (bluish)."],"metadata":{}},{"cell_type":"markdown","source":["#### Evaluating K Value"],"metadata":{}},{"cell_type":"code","source":["cost = list()\nfor k in range(2,11):\n    bkm = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    bkm_model = bkm.fit(colors_assembled)\n    cost.append(bkm_model.computeCost(colors_assembled)/k)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,11), cost, 'b*-')\nplt.xlabel('Number of clusters');\nplt.ylabel('Within Set Sum of Squared Error');\nplt.title('Elbow for K-Means clustering');\n# Uncomment the next line\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["### **Best k value**\n#####From the above scree plot, we have k=4 as the elbow point which signifies it to be the best k-value"],"metadata":{}},{"cell_type":"markdown","source":["### 6) Use both tags and colors for k-means clustering\n\nPerform k-means clustering on the paintings using *both* tag and color columns. Decide a good value for k, execute the clustering, display the images in each clusters, and describe the resulting clusters."],"metadata":{}},{"cell_type":"code","source":["ct = spark.createDataFrame(bob_ross[all_columns[:-1]])\n\nassembler = VectorAssembler(\n    inputCols=all_columns[:-1],\n    outputCol=\"features\")\n\nall_assembled = assembler.transform(ct)\n\n\n# create a k-means model, k=4, and fit the data\nkmeans = KMeans().setK(4).setSeed(1)\nkmeans_model = kmeans.fit(all_assembled.select(\"features\"))\n\n# Make predictions\nall_predictions = kmeans_model.transform(all_assembled)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["#clustering column - prediction\nbob_ross[\"prediction\"] = all_predictions.select(\"prediction\").toPandas().set_index(bob_ross.index)\n\ndf_all0 = bob_ross[bob_ross[\"prediction\"] == 0]\ndisplay_images(df_all0['image'],\" Cluster 1 Images (Both by tags & colors)\")"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":["#### Analysis : On observing the above cluster, we find that all images have an element of Mountains, Lake, Summer Evenings (Tags) + bright and blue color (Color)"],"metadata":{}},{"cell_type":"code","source":["df_all1 = bob_ross[bob_ross[\"prediction\"] == 1]\ndisplay_images(df_all1['image'],\" Cluster 2 Images (Both by tags & colors)\")"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":["#### Analysis : On observing the above cluster, we find that all images have an elements of Snow Mountains and Winter(tags) + Pale Blue shade(color)"],"metadata":{}},{"cell_type":"code","source":["df_all2 = bob_ross[bob_ross[\"prediction\"] == 2]\ndisplay_images(df_all2['image'],\" Cluster 3 Images (Both by tags & colors)\")"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":["#### Analysis : On observing the above cluster, we find that all images have an element of Lakes, Spring, Waterfalls (Tags) + green/nature color (Color)"],"metadata":{}},{"cell_type":"code","source":["df_all3 = bob_ross[bob_ross[\"prediction\"] == 3]\ndisplay_images(df_all3['image'],\" Cluster 4 Images (Both by tags & colors)\")"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":["#### Analysis : On observing the above cluster, we find that all images have an element of Ocean View, Waves, Steve Ross (Tags) + Dark color (Color)"],"metadata":{}},{"cell_type":"markdown","source":["### **Best k value**"],"metadata":{}},{"cell_type":"code","source":["cost = list()\nfor k in range(2,11):\n    bkm = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    bkm_model = bkm.fit(all_assembled)\n    cost.append(bkm_model.computeCost(all_assembled)/k)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,11), cost, 'b*-')\nplt.xlabel('Number of clusters');\nplt.ylabel('Within Set Sum of Squared Error');\nplt.title('Elbow for K-Means clustering');\n# Uncomment the next line\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":["### Silhouette Plots"],"metadata":{}},{"cell_type":"code","source":["cost = list()\nevaluator = ClusteringEvaluator()\nfor k in range(2,11):\n    bkm = KMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    bkm_model = bkm.fit(all_assembled)\n    all_predictions = bkm_model.transform(all_assembled)\n    silhouette = evaluator.evaluate(all_predictions)\n    cost.append(silhouette)\n    \nkIdx = np.argmax(cost)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,11), cost, 'b*-')\nplt.plot(range(2,11)[kIdx], cost[kIdx], marker='o', markersize=12, \n         markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\nplt.xlim(1, plt.xlim()[1])\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Coefficient')\nplt.title('Silhouette Scores for k-means clustering')\n# Uncomment the next line\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["### **Best k value**\n#####From the scree plot and silhouette plot, we have k=4 as the elbow point and a peak in sil plot which signifies it to be the best k-value, hence we need to reiterate with k=4"],"metadata":{}},{"cell_type":"markdown","source":["## Above and Beyond\n\n#### Repeating the analysis for Step 6 (both tags and colors) using bisecting k-means **and compare the results to k-means**."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.clustering import BisectingKMeans\n\n\nct_bisect = spark.createDataFrame(bob_ross[all_columns[:-1]])\n\nassembler = VectorAssembler(\n    inputCols=all_columns[:-1],\n    outputCol=\"features\")\n\nall_assembled = assembler.transform(ct_bisect)\n\n\n# Trains a bisecting k-means model.\nbkm = BisectingKMeans().setK(3).setSeed(1)\nbkm_model = bkm.fit(all_assembled.select(\"features\"))\n\n# Make predictions\nall_predictions = bkm_model.transform(all_assembled)\n\n# Evaluate clustering by computing Within Set Sum of Squared Errors.\ncost = bkm_model.computeCost(all_assembled)\nprint(\"Within Set Sum of Squared Errors = \" + str(cost))\n"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["bob_ross[\"prediction\"] = all_predictions.select(\"prediction\").toPandas().set_index(bob_ross.index)\n\ndf_all0_bkm = bob_ross[bob_ross[\"prediction\"] == 0]\ndisplay_images(df_all0_bkm['image'],\" Cluster 1 Images (Both by tags & colors) - BKM Model\")"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["df_all1_bkm = bob_ross[bob_ross[\"prediction\"] == 1]\ndisplay_images(df_all1_bkm['image'],\" Cluster 2 Images (Both by tags & colors) - BKM Model\")"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["df_all2_bkm = bob_ross[bob_ross[\"prediction\"] == 2]\ndisplay_images(df_all2_bkm['image'],\" Cluster 3 Images (Both by tags & colors) - BKM Model\")"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["np.sqrt(all_assembled.count()/2)"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["cost = list()\nfor k in range(2,11):\n    bkm = BisectingKMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    bkm_model = bkm.fit(all_assembled)\n    cost.append(bkm_model.computeCost(all_assembled)/k)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,11), cost, 'b*-')\nplt.xlabel('Number of clusters');\nplt.ylabel('Within Set Sum of Squared Error');\nplt.title('Elbow for bisecting K-Means clustering');\n# Uncomment the next line\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["cost = list()\nevaluator = ClusteringEvaluator()\nfor k in range(2,11):\n    bkm = BisectingKMeans().setK(k).setSeed(1).setFeaturesCol(\"features\")\n    bkm_model = bkm.fit(all_assembled)\n    all_predictions = bkm_model.transform(all_assembled)\n    silhouette = evaluator.evaluate(all_predictions)\n    cost.append(silhouette)\n    \nkIdx = np.argmax(cost)\n\nfig, ax = plt.subplots()\nplt.plot(range(2,11), cost, 'b*-')\nplt.plot(range(2,11)[kIdx], cost[kIdx], marker='o', markersize=12, \n         markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\nplt.xlim(1, plt.xlim()[1])\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Coefficient')\nplt.title('Silhouette Scores for bisect k-means clustering')\n# Uncomment the next line\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":["## Differences between K means and Bisecting K means clustering :\n\nWe can clearly see the differences between the cluster images. K means clustering has a mixture of different kind of images in the clusters whereas the bisecting k means cluster images are much more similar and less ambiguous.\nOne can clearly make out the differences in different bisecting k means clusters like :\nCluster 1 is Ocean view only, Cluster 2 is no mountains but lake view only, whereas Cluster 3 is mountains and trees.\n\nThere is clear difference in the both Silhouette plots. K means sil plot suggesting k = 2(not a good result), whereas bisecting k means suggest k = 3. Furthermore, the best k -value as suggested by both the sil plot and scree plot varies in K means while it is quite similar in bisecting k means which suggests k=3 to be the best k value.\n\nHence, bisecting k means provides better looking clusters than k means."],"metadata":{}}],"metadata":{"name":"HW7","notebookId":1096380985162052},"nbformat":4,"nbformat_minor":0}
